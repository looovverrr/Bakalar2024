{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3709d60d-8a18-453e-b00a-19a2ae7507f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.64.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.8.2 optuna-3.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4cbc52a-77ed-48e8-bf88-80a26acc3b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.10/site-packages (from imblearn) (0.12.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabea180-8813-43dc-9b57-add6070386a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"trainschybou.csv\")\n",
    "test_data=pd.read_csv(\"test_data.csv\")\n",
    "train_data=train_data.drop(\"I am currently employed at least part-time\",axis=1)\n",
    "test_data=test_data.drop(\"I am currently employed at least part-time\",axis=1)\n",
    "columns_order = train_data.columns.tolist()\n",
    "test_data = test_data[columns_order]\n",
    "y_train = train_data['Unemployed']\n",
    "X_train = train_data.drop(columns=('Unemployed'))\n",
    "y_test = test_data['Unemployed']\n",
    "X_test = test_data.drop(columns=('Unemployed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e070c-9709-4d57-8b15-2c641204f62d",
   "metadata": {},
   "source": [
    "# Pre výber hyperparametrov bol použity nastroj Optuna.  Každý kód pre každý model som použila vela krát s rôznym počtom n_trials a najlepšie parametre už boli použité pri modelovaní"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe84a2-d229-4e8c-aac8-0a3426fd1c45",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c79d6a-c716-4c67-9a1d-8027d7d12b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 50)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    p = trial.suggest_int('p', 1, 5) \n",
    "    leaf_size = trial.suggest_int('leaf_size', 10, 50)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, p=p, leaf_size=leaf_size, algorithm=algorithm)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "    return f1_class1\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=150)\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "best_model = KNeighborsClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1_class1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print(\"F1 Score for class 1:\", f1_class1)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_train_first_model = train_data['Unemployed']\n",
    "X_train_first_model = train_data.drop(columns=('Unemployed'))\n",
    "y_test_first_model = test_data['Unemployed']\n",
    "X_test_first_model = test_data.drop(columns=('Unemployed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a4266-6b18-4b58-b66a-a5d7c2ae7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 40)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    p = trial.suggest_int('p', 1, 5)  \n",
    "    leaf_size = trial.suggest_int('leaf_size', 10, 100)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "    n_neighbors_adasyn = trial.suggest_int('n_neighbors_adasyn', 1, 50)  \n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, p=p, leaf_size=leaf_size, algorithm=algorithm)\n",
    "    adasyn = ADASYN(n_neighbors=n_neighbors_adasyn, random_state=42)\n",
    "    X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1_class1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "\n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = KNeighborsClassifier(**{k: v for k, v in best_params.items() if k != 'n_neighbors_adasyn'})\n",
    "\n",
    "adasyn = ADASYN(n_neighbors=best_params['n_neighbors_adasyn'], random_state=42)\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "f1_class1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print(\"F1 Score for class 1:\", f1_class1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de167262-5543-4933-872a-d4161ac6be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "def objective(trial):\n",
    "\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 50)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    p = trial.suggest_int('p', 1, 5)  \n",
    "    leaf_size = trial.suggest_int('leaf_size', 10, 60)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "    k_neighbors_smote = trial.suggest_int('k_neighbors_smote', 1, 35)  # Число соседей для SMOTE\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, p=p, leaf_size=leaf_size, algorithm=algorithm)\n",
    "\n",
    "    smote = SMOTE(k_neighbors=k_neighbors_smote, random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "    \n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = KNeighborsClassifier(**{k: v for k, v in best_params.items() if k != 'k_neighbors_smote'})\n",
    "\n",
    "smote = SMOTE(k_neighbors=best_params['k_neighbors_smote'], random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "f1_class1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print(\"F1 Score for class 1:\", f1_class1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7260a-3a57-4c7f-ac45-a0b39cd866e5",
   "metadata": {},
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d46b2-de52-47c3-b145-e8e8ffdb3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 50)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 50)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    \n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "    \n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "f1_class1 = f1_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "print(\"F1 Score for class 1:\", f1_class1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bffef0-8508-4477-ab85-e4f1dee8e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 30)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 30)\n",
    "    k_neighbors = trial.suggest_int('k_neighbors', 5, 40)\n",
    "\n",
    "    smote = SMOTE(random_state=42, k_neighbors=k_neighbors, sampling_strategy='minority')\n",
    "    X_resampled_train, y_resampled_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model = DecisionTreeClassifier(criterion=criterion,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   random_state=42)\n",
    "    \n",
    "    model.fit(X_resampled_train, y_resampled_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    return f1_class_1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "best_params = study.best_params\n",
    "k_neighbors = best_params.pop('k_neighbors')\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(\"  Criterion:\", best_params['criterion'])\n",
    "print(\"  Max Depth:\", best_params['max_depth'])\n",
    "print(\"  Min Samples Split:\", best_params['min_samples_split'])\n",
    "print(\"  Min Samples Leaf:\", best_params['min_samples_leaf'])\n",
    "print(\"  Number of Neighbors (for SMOTE):\", k_neighbors)\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=k_neighbors, sampling_strategy='minority')\n",
    "X_resampled_train, y_resampled_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "best_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_resampled_train, y_resampled_train)\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "f1_class_1_best = f1_score(y_test, y_pred_best, pos_label=1)\n",
    "print(\"F1 Score for class 1 with best parameters:\", f1_class_1_best)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e48c4a-4734-4ab2-9725-44e1a63ffb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 100)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 30)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 30)\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 5, 50)\n",
    "\n",
    "    adasyn = ADASYN(random_state=42, n_neighbors=n_neighbors, sampling_strategy='minority')\n",
    "    X_resampled_train, y_resampled_train = adasyn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model = DecisionTreeClassifier(criterion=criterion,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   random_state=42)\n",
    "    \n",
    "    model.fit(X_resampled_train, y_resampled_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    return f1_class_1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "best_params = study.best_params\n",
    "n_neighbors = best_params.pop('n_neighbors')\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(\"  Criterion:\", best_params['criterion'])\n",
    "print(\"  Max Depth:\", best_params['max_depth'])\n",
    "print(\"  Min Samples Split:\", best_params['min_samples_split'])\n",
    "print(\"  Min Samples Leaf:\", best_params['min_samples_leaf'])\n",
    "print(\"  Number of Neighbors (for ADASYN):\", n_neighbors)\n",
    "\n",
    "adasyn = ADASYN(random_state=42, n_neighbors=n_neighbors, sampling_strategy='minority')\n",
    "X_resampled_train, y_resampled_train = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "best_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_resampled_train, y_resampled_train)\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "f1_class_1_best = f1_score(y_test, y_pred_best, pos_label=1)\n",
    "print(\"F1 Score for class 1 with best parameters:\", f1_class_1_best)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61314bd-6ecd-43e9-8355-0a71af7dda53",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc0f9d-b6d0-4816-8e10-512a46ca1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        criterion=\"entropy\",\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = RandomForestClassifier(**best_params, criterion=\"gini\", random_state=42)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(\"F1 Score for class 1:\", f1_class1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961eb0d6-e61a-4317-831d-032161f55020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 40)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 30)\n",
    "    k_neighbors = trial.suggest_int('k_neighbors', 5, 50)\n",
    "    \n",
    "    smote = SMOTE(random_state=42, k_neighbors=k_neighbors, sampling_strategy='minority')\n",
    "    X_resampled_train, y_resampled_train = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        criterion=\"entropy\",\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_resampled_train, y_resampled_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "smote = SMOTE(random_state=42, k_neighbors=best_params['k_neighbors'], sampling_strategy='minority')\n",
    "X_resampled_train, y_resampled_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                                    max_depth=best_params['max_depth'],\n",
    "                                    min_samples_split=best_params['min_samples_split'],\n",
    "                                    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                    criterion=\"entropy\",\n",
    "                                    random_state=42)\n",
    "\n",
    "best_model.fit(X_resampled_train, y_resampled_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(\"F1 Score for class 1:\", f1_class1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885f724-6531-41ec-97ef-25be1de18ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 50)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 100)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 30)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 30)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 5, 50)\n",
    "    \n",
    "    adasyn = ADASYN(random_state=42, n_neighbors=n_neighbors, sampling_strategy='minority')\n",
    "    X_resampled_train, y_resampled_train = adasyn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        criterion=criterion,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_resampled_train, y_resampled_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "adasyn = ADASYN(random_state=42, n_neighbors=best_params['n_neighbors'], sampling_strategy='minority')\n",
    "X_resampled_train, y_resampled_train = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "best_model = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    criterion=best_params['criterion'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_model.fit(X_resampled_train, y_resampled_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "print(\"F1 Score for class 1:\", f1_class1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0358bb73-a8d5-4168-9948-b8f307907c77",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2829ef0-d7ee-4e16-952e-cda08b471f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False,\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'eta': trial.suggest_loguniform('eta', 1e-8, 1.0),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0, step=0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.1),\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36614120-c99f-4639-bb87-ed9914f48d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False,\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'eta': trial.suggest_loguniform('eta', 1e-8, 1.0),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0, step=0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.1),\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    smote = SMOTE(random_state=42, k_neighbors=trial.suggest_int('k_neighbors', 1, 50))\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('smote', smote),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_smote = SMOTE(random_state=42, k_neighbors=best_params['k_neighbors'])\n",
    "\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    ('smote', best_smote),\n",
    "    ('model', best_model)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf027a34-3663-4a88-8d57-ea1b8ca23ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False,\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'eta': trial.suggest_loguniform('eta', 1e-8, 1.0),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0, step=0.1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.1),\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    adasyn = ADASYN(random_state=42, n_neighbors=trial.suggest_int('n_neighbors', 1, 50))\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('adasyn', adasyn),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    f1_class1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    return f1_class1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_adasyn = ADASYN(random_state=42, n_neighbors=best_params['n_neighbors'])\n",
    "\n",
    "best_model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    ('adasyn', best_adasyn),\n",
    "    ('model', best_model)\n",
    "])\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
